{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df544dd3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da1b323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549f1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = kagglehub.dataset_download(\"sidharkal/sports-image-classification\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf88933",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "images_dir = \"../data/dataset/\"\n",
    "train_dir = images_dir + \"train/\"\n",
    "\n",
    "badminton_train_dir = train_dir + \"Badminton/\"\n",
    "tennis_train_dir = train_dir + \"Tennis/\"\n",
    "cricket_train_dir = train_dir + \"Cricket/\"\n",
    "soccer_train_dir = train_dir + \"Soccer/\"\n",
    "swimming_train_dir = train_dir + \"Swimming/\"\n",
    "karate_train_dir = train_dir + \"Karate/\"\n",
    "wrestling_train_dir = train_dir + \"Wrestling/\"\n",
    "\n",
    "test_dir = images_dir + \"test/\"\n",
    "\n",
    "badminton_test_dir = test_dir + \"Badminton/\"\n",
    "tennis_test_dir = test_dir + \"Tennis/\"\n",
    "cricket_test_dir = test_dir + \"Cricket/\"\n",
    "soccer_test_dir = test_dir + \"Soccer/\"\n",
    "swimming_test_dir = test_dir + \"Swimming/\"\n",
    "karate_test_dir = test_dir + \"Karate/\"\n",
    "wrestling_test_dir = test_dir + \"Wrestling/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb00c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1db7f116f50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f94437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.copytree(path, data_dir, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47f18e",
   "metadata": {},
   "source": [
    "## Dataset class and data manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a9fcb",
   "metadata": {},
   "source": [
    "### Dataset class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a4878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0441cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset1(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None, is_train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory with all the class folders\n",
    "            classes (list): List of class names (subfolder names)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "            is_train (bool): Whether this is training data or not\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        # Default transforms if none provided\n",
    "        if self.transform is None:\n",
    "            if is_train:\n",
    "                self.transform = T.Compose([\n",
    "                    T.RandomResizedCrop(128), # Resize to 128x128\n",
    "                    # T.RandomHorizontalFlip(),\n",
    "                    # T.RandomRotation(15),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(128), # Resize to 128x128\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "\n",
    "        for idx, cls in enumerate(classes):\n",
    "            class_folder = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    self.samples.append((img_path, idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx, retry=0):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            if retry < 3:\n",
    "                return self.__getitem__(random.randint(0, len(self)-1), retry=retry+1)\n",
    "            else:\n",
    "                raise RuntimeError(\"Too many failed image loads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67989cb",
   "metadata": {},
   "source": [
    "### Dataset class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb55162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset2(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None, is_train=True, split_ratio=0.8, seed=42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory with all the class folders\n",
    "            classes (list): List of class names (subfolder names)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "            is_train (bool): Whether this is training data or not\n",
    "            split_ratio (float): Ratio for training data (default is 0.8)\n",
    "            seed (int): Seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        all_samples = []\n",
    "        for idx, cls in enumerate(classes):\n",
    "            class_folder = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    all_samples.append((img_path, idx))\n",
    "\n",
    "        # Shuffle and split once\n",
    "        random.seed(seed)\n",
    "        random.shuffle(all_samples)\n",
    "        split_point = int(len(all_samples) * split_ratio)\n",
    "        if is_train:\n",
    "            self.samples = all_samples[:split_point]\n",
    "        else:\n",
    "            self.samples = all_samples[split_point:]\n",
    "\n",
    "        # Set default transforms if not provided\n",
    "        if self.transform is None:\n",
    "            if is_train:\n",
    "                self.transform = T.Compose([\n",
    "                    T.RandomResizedCrop(128),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(128),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx, retry=0):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            if retry < 3:\n",
    "                return self.__getitem__(random.randint(0, len(self)-1), retry=retry+1)\n",
    "            else:\n",
    "                raise RuntimeError(\"Too many failed image loads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe87c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e39779",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afb3d6",
   "metadata": {},
   "source": [
    "### Model 1: Simple CNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744d80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplenet1(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(Simplenet1, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1), # 128 128 3 -> 128 128 64 \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 128 128 64 -> 64 64 64\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 64 64 64 -> 64 64 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 64 64 128 -> 32 32 128\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # 32 32 128 -> 32 32 256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 32 32 256 -> 16 16 256\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1), # 16 16 256 -> 16 16 512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 16 16 512 -> 8 8 512\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), # 8 8 512 -> 1 1 512\n",
    "            nn.Flatten(), # 1 1 512 -> 512\n",
    "            nn.Linear(512, 256), # 512 -> 256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5), # Dropout layer\n",
    "            nn.Linear(256, 128), # 256 -> 128\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5), # Dropout layer\n",
    "            nn.Linear(128, num_classes), # 128 -> num_classes\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937d1b7",
   "metadata": {},
   "source": [
    "### Model 2: Simple CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57adfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplenet2(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(Simplenet2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False), # 128x128x3 → 128x128x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False), # 128x128x64 → 128x128x64\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 128x128x64 → 64x64x64\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False), # 64x64x64 → 64x64x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False), # 64x64x128 → 64x64x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 64x64x128 → 32x32x128\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False), # 32x32x128 → 32x32x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False), # 32x32x256 → 32x32x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 32x32x256 → 16x16x256\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=False), # 16x16x256 → 16x16x512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False), # 16x16x512 → 16x16x512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 16x16x512 → 8x8x512\n",
    "\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1, bias=False), # 8x8x512 → 8x8x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2) # 8x8x256 → 4x4x256\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                  # 4x4x256 = 4096\n",
    "            nn.Linear(256 * 4 * 4, 512),   # 4096 → 512\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)   # 512 → num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed47e16",
   "metadata": {},
   "source": [
    "### Model 3: Simple CNN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e928dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet3(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleNet3, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2), # 128 128 3 -> 63 63 64\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # 63 63 64 -> 31 31 64\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # 31 31 64 -> 14 14 128\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), #   14 14 128 -> 7 7 128\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2), # 7 7 128 -> 3 3 256\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(288, 144),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(144, 72),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(72, 36),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(36, 18),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(18, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6d285",
   "metadata": {},
   "source": [
    "### Model 4: Simple CNN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3998721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet4(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleNet4, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), # 128 128 3 -> 128 128 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 128 128 32 -> 64 64 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),   # 64 64 32 -> 64 64 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 64 64 64 -> 32 32 64\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 32 32 64 -> 16 16 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 16 16 128 -> 8 8 128\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),#   -> 4 x 4 x 256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e76ad",
   "metadata": {},
   "source": [
    "# Utils for Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01459865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all_but_last_n(model, n=2):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Get all modules with parameters\n",
    "    modules_with_params = [m for m in model.modules() if any(p.requires_grad is False for p in m.parameters())]\n",
    "\n",
    "    # Unfreeze last n modules with parameters\n",
    "    for module in modules_with_params[-n:]:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def print_trainable_params(model):\n",
    "    print(\"Trainable Parameters:\")\n",
    "    total = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            # print(f\"{name}: {num_params}\")\n",
    "            total += num_params\n",
    "    print(f\"Total Trainable Parameters: {total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3f81b",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e879f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    if model_name == \"simplenet1\":\n",
    "        return Simplenet1()\n",
    "    \n",
    "    elif model_name == \"simplenet2\":\n",
    "        return Simplenet2()\n",
    "    \n",
    "    elif model_name == \"simplenet3\":\n",
    "        return SimpleNet3()\n",
    "    \n",
    "    elif model_name == \"simplenet4\":\n",
    "        return SimpleNet4()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not recognized. Please choose a valid model name.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1d69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(config, transform=None):\n",
    "    dataset_type = config[\"dataset_class\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    seed = 42 \n",
    "\n",
    "    if dataset_type == \"ImageClass1\": # using train and test directories\n",
    "        train_dataset = ImageDataset1(root_dir=train_dir, transform=transform, classes=classes, is_train=True)\n",
    "        val_dataset = ImageDataset1(root_dir=test_dir, transform=transform, classes=classes, is_train=False)\n",
    "    else: # Splitting train into train and validation sets\n",
    "        train_dataset = ImageDataset2(\n",
    "            root_dir=train_dir,\n",
    "            classes=classes,\n",
    "            transform=transform,\n",
    "            is_train=True,\n",
    "            split_ratio=0.8,\n",
    "            seed=seed\n",
    "        )\n",
    "        val_dataset = ImageDataset2(\n",
    "            root_dir=train_dir,\n",
    "            classes=classes,\n",
    "            transform=transform,\n",
    "            is_train=False,\n",
    "            split_ratio=0.8,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return val_loss / len(val_loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf874459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model, method):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            if method == \"xavier\":\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif method == \"kaiming\":\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "\n",
    "def should_initialize(model_type):\n",
    "    return model_type == \"scratch\"  # only initialize scratch models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2276ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_model(config):\n",
    "    model_type , model_name = config[\"model_choice\"]\n",
    "    train_loader, val_loader = get_dataloaders(config)\n",
    "\n",
    "    init_method = config[\"init_method\"]\n",
    "\n",
    "    model = load_model(model_name)\n",
    "    model.to(device)\n",
    "    time_stamp = datetime.now().strftime(\"%Y%m%d_%H\")\n",
    "    unique_config = f\"{model_name}_{config['dataset_class']}_{config['optimizer']}_{config['init_method']}_{config['batch_size']}_{config['lr']}_time_{time_stamp}\"\n",
    "\n",
    "    if should_initialize(config[\"model_choice\"][0]) and init_method != \"default\":\n",
    "        initialize_weights(model, init_method)\n",
    "\n",
    "    # Optimizer\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "    else:\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    epochs = config[\"epochs\"]\n",
    "    save_interval = 2 if model_type == \"pretrained\" else 50\n",
    "    save_dir = os.path.join(\"logs_128_scratch\", \"checkpoints\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    total_batches = len(train_loader)\n",
    "    total_steps = epochs * total_batches\n",
    "    progress_bar = tqdm(total=total_steps, dynamic_ncols=True, desc=\"Training\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Update tqdm\n",
    "            train_loss = running_loss / (i + 1)\n",
    "            train_acc = 100. * correct / total\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix({\n",
    "                \"Epoch\": f\"{epoch+1}/{epochs}\",\n",
    "                \"Train Loss\": f\"{train_loss:.4f}\",\n",
    "                \"Train Acc\": f\"{train_acc:.2f}%\"\n",
    "            })\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate_model(model, val_loader, criterion)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            os.makedirs(os.path.join(save_dir, unique_config), exist_ok=True)\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, unique_config, f\"epoch_{epoch+1}.pt\"))\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 20:\n",
    "                progress_bar.set_description(\"Early Stopping\")\n",
    "                break\n",
    "    \n",
    "        progress_bar.set_postfix({\"Epoch\": f\"{epoch+1}/{epochs}\", \"Train Loss\": f\"{train_loss:.4f}\", \"Train Acc\": f\"{train_acc:.2f}%\", \"Val Loss\": f\"{val_loss:.4f}\", \"Val Acc\": f\"{val_acc:.2f}%\"})\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Save metrics\n",
    "    os.makedirs(os.path.join(save_dir, unique_config), exist_ok=True)\n",
    "    torch.save({\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"train_accs\": train_accs,\n",
    "        \"val_accs\": val_accs\n",
    "    }, os.path.join(save_dir, unique_config, \"metrics.pt\"))\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, unique_config, \"final_model.pt\"))\n",
    "\n",
    "    return max(val_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721fa7fa",
   "metadata": {},
   "source": [
    "## Manual Configurations Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a575dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet2\"),\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 16,\n",
    "    \"dataset_class\": \"ImageClass2\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"xavier\",\n",
    "}\n",
    "\n",
    "config2 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet1\"),\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 32,\n",
    "    \"dataset_class\": \"ImageClass2\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"xavier\",\n",
    "}\n",
    "\n",
    "config3 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet4\"),\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 32,\n",
    "    \"dataset_class\": \"ImageClass2\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"kaiming\",\n",
    "}\n",
    "\n",
    "config4 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet3\"),\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 64,\n",
    "    \"dataset_class\": \"ImageClass1\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"kaiming\",\n",
    "}\n",
    "\n",
    "config5 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet2\"),\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 16,\n",
    "    \"dataset_class\": \"ImageClass2\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"xavier\",\n",
    "}\n",
    "\n",
    "config6 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet1\"),\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 16,\n",
    "    \"dataset_class\": \"ImageClass2\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"xavier\",\n",
    "}\n",
    "\n",
    "config7 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet3\"),\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 64,\n",
    "    \"dataset_class\": \"ImageClass2\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"kaiming\",\n",
    "}\n",
    "\n",
    "config8 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet4\"),\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 32,\n",
    "    \"dataset_class\": \"ImageClass1\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"xavier\",\n",
    "}\n",
    "\n",
    "config9 = {\n",
    "    \"model_choice\": (\"scratch\", \"simplenet2\"),\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 16,\n",
    "    \"dataset_class\": \"ImageClass2\",\n",
    "    \"epochs\": 100,\n",
    "    \"init_method\": \"xavier\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9982f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early Stopping:  66%|██████▌   | 6798/10300 [50:46<26:09,  2.23it/s, Epoch=66/100, Train Loss=0.7448, Train Acc=73.89%]                             \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70.53462940461725"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 7 (1 hr)\n",
    "train_model(config7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "479b8ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12900/12900 [1:47:28<00:00,  2.00it/s, Epoch=100/100, Train Loss=0.7692, Train Acc=73.50%, Val Loss=0.9623, Val Acc=68.58%] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.16342412451363"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 4 (1.5 hr)\n",
    "train_model(config4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c85a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early Stopping:  60%|██████    | 12360/20600 [2:22:42<1:35:08,  1.44it/s, Epoch=60/100, Train Loss=1.0762, Train Acc=60.77%]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.00121506682868"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 3 (3 hr)\n",
    "train_model(config3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c21e25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early Stopping:  27%|██▋       | 6966/25800 [1:21:23<3:40:03,  1.43it/s, Epoch=27/100, Train Loss=1.8845, Train Acc=18.91%]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.43385214007782"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 8 (3.5 hr)\n",
    "train_model(config8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de57a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early Stopping:  88%|████████▊ | 36256/41200 [7:38:12<1:02:29,  1.32it/s, Epoch=88/100, Train Loss=1.1198, Train Acc=59.44%]                             \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.60388821385176"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 6 (6.5 hr)\n",
    "train_model(config6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6119ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20600/20600 [10:11:16<00:00,  1.78s/it, Epoch=100/100, Train Loss=0.8173, Train Acc=72.63%, Val Loss=0.7938, Val Acc=72.90%] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.57229647630619"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 2 (7.5 hr)\n",
    "train_model(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60fe54b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early Stopping:  66%|██████▌   | 27192/41200 [17:17:52<8:54:39,  2.29s/it, Epoch=66/100, Train Loss=0.6828, Train Acc=76.46%]                             \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.8809234507898"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 5 (17 hr)\n",
    "train_model(config5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b567f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early Stopping:  73%|███████▎  | 30076/41200 [18:14:22<6:44:46,  2.18s/it, Epoch=73/100, Train Loss=1.0079, Train Acc=64.14%]                             \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.15552855407047"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 1 (17.5 hr)\n",
    "train_model(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b22bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early Stopping:  96%|█████████▌| 39552/41200 [23:31:14<58:48,  2.14s/it, Epoch=96/100, Train Loss=0.6731, Train Acc=76.74%]                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.94167679222357"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 9 (18 hr)\n",
    "train_model(config9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
