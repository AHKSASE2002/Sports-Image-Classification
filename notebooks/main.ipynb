{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df544dd3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da1b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549f1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = kagglehub.dataset_download(\"sidharkal/sports-image-classification\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf88933",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "images_dir = \"../data/dataset/\"\n",
    "train_dir = images_dir + \"train/\"\n",
    "\n",
    "badminton_train_dir = train_dir + \"Badminton/\"\n",
    "tennis_train_dir = train_dir + \"Tennis/\"\n",
    "cricket_train_dir = train_dir + \"Cricket/\"\n",
    "soccer_train_dir = train_dir + \"Soccer/\"\n",
    "swimming_train_dir = train_dir + \"Swimming/\"\n",
    "karate_train_dir = train_dir + \"Karate/\"\n",
    "wrestling_train_dir = train_dir + \"Wrestling/\"\n",
    "\n",
    "test_dir = images_dir + \"test/\"\n",
    "\n",
    "badminton_test_dir = test_dir + \"Badminton/\"\n",
    "tennis_test_dir = test_dir + \"Tennis/\"\n",
    "cricket_test_dir = test_dir + \"Cricket/\"\n",
    "soccer_test_dir = test_dir + \"Soccer/\"\n",
    "swimming_test_dir = test_dir + \"Swimming/\"\n",
    "karate_test_dir = test_dir + \"Karate/\"\n",
    "wrestling_test_dir = test_dir + \"Wrestling/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb00c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27ae8b2af30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f94437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.copytree(path, data_dir, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd987c4",
   "metadata": {},
   "source": [
    "## Organizing Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the train.csv , test.csv\n",
    "train_df = pd.read_csv(images_dir +\"/train.csv\")\n",
    "test_df = pd.read_csv(images_dir +\"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c190640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index(\"image_ID\", inplace=True), test_df.set_index(\"image_ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c6d25",
   "metadata": {},
   "source": [
    "### Moving data to be per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df[\"label\"].unique()\n",
    "\n",
    "for label in labels:\n",
    "    os.makedirs(train_dir + label, exist_ok=True)\n",
    "    os.makedirs(test_dir + label, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e31640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc['7c225f7b61.jpg']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cecaf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b94fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_df)):\n",
    "    image_id = train_df.index[i]\n",
    "    label = train_df['label'][i]\n",
    "    old_path = train_dir + image_id\n",
    "    new_path = train_dir + label + \"/\" + image_id\n",
    "    if os.path.exists(old_path):\n",
    "        shutil.move(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3972a",
   "metadata": {},
   "source": [
    "### Labeling Test data as it was unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1efbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']\n",
    "\n",
    "def classify_with_clip(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(text=classes, images=image, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image \n",
    "    probs = logits_per_image.softmax(dim=1)\n",
    "    pred = probs.argmax()\n",
    "    return classes[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae52915",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(test_df))):\n",
    "    image_id = test_df.index[i]\n",
    "    image_path = test_dir + image_id\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "    label = classify_with_clip(image_path)\n",
    "    test_df.at[image_id, 'label'] = label\n",
    "    new_path = test_dir + label + \"/\" + image_id\n",
    "    if os.path.exists(image_path):\n",
    "        shutil.move(image_path, new_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14467c",
   "metadata": {},
   "source": [
    "## Statistics from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5b7a6",
   "metadata": {},
   "source": [
    "### Checking distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']\n",
    "\n",
    "train_dirs = [train_dir + cls + \"/\" for cls in classes]\n",
    "test_dirs = [test_dir + cls + \"/\" for cls in classes]\n",
    "\n",
    "train_counts = [len(os.listdir(d)) if os.path.exists(d) else 0 for d in train_dirs]\n",
    "test_counts = [len(os.listdir(d)) if os.path.exists(d) else 0 for d in test_dirs]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axs[0].bar(classes, train_counts, color='skyblue')\n",
    "axs[0].set_title('Train Class Distribution')\n",
    "axs[0].set_xlabel('Class')\n",
    "axs[0].set_ylabel('Number of Images')\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axs[1].bar(classes, test_counts, color='lightgreen')\n",
    "axs[1].set_title('Test Class Distribution')\n",
    "axs[1].set_xlabel('Class')\n",
    "axs[1].set_ylabel('Number of Images')\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf74727",
   "metadata": {},
   "source": [
    "### Per class statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(classes))  \n",
    "width = 0.35  \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width/2, train_counts, width, label='Train', color='skyblue')\n",
    "rects2 = ax.bar(x + width/2, test_counts, width, label='Test', color='lightgreen')\n",
    "\n",
    "ax.set_ylabel('Number of Images')\n",
    "ax.set_title('Per-Class Distribution: Train vs Test')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "def annotate_bars(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "annotate_bars(rects1)\n",
    "annotate_bars(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6fd0e",
   "metadata": {},
   "source": [
    "### Pixel Value Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_brightness = {cls: [] for cls in classes}\n",
    "\n",
    "for cls, folder in zip(classes, train_dirs):\n",
    "    if not os.path.exists(folder):\n",
    "        continue\n",
    "    for img_file in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_file)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"L\")  \n",
    "            img_arr = np.array(img)\n",
    "            mean_brightness = img_arr.mean()\n",
    "            class_brightness[cls].append(mean_brightness)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {img_path}: {e}\")\n",
    "\n",
    "# Plot distributions\n",
    "fig, axs = plt.subplots(len(classes), 1, figsize=(8, len(classes)*3))\n",
    "\n",
    "for idx, cls in enumerate(tqdm(classes)):\n",
    "    axs[idx].hist(class_brightness[cls], bins=30, color='skyblue', edgecolor='black', density=True)\n",
    "    axs[idx].set_title(f'Pixel Distribution: {cls}')\n",
    "    axs[idx].set_xlabel('Mean Pixel Values')\n",
    "    axs[idx].set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced7447",
   "metadata": {},
   "source": [
    "- Pixels values are distributed well across all the images meaning that the images are not too dark or too bright.\n",
    "- Thus images is considered to be well exposed and not too dark or too bright so little noise are added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70951540",
   "metadata": {},
   "source": [
    "## Showing some images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978da631",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(classes), 2, figsize=(8, len(classes) * 3))\n",
    "\n",
    "for row_idx, (cls, folder) in enumerate(zip(classes, train_dirs)):\n",
    "    if not os.path.exists(folder):\n",
    "        continue\n",
    "    images = [f for f in os.listdir(folder) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "    selected_images = images[:2]  \n",
    "    for col_idx in range(2):\n",
    "        if col_idx < len(selected_images):\n",
    "            img_path = os.path.join(folder, selected_images[col_idx])\n",
    "            img = Image.open(img_path)\n",
    "            axs[row_idx, col_idx].imshow(img)\n",
    "            axs[row_idx, col_idx].axis('off')\n",
    "            if col_idx == 0:\n",
    "                axs[row_idx, col_idx].set_title(f\"{cls} - Sample 1\")\n",
    "            else:\n",
    "                axs[row_idx, col_idx].set_title(f\"{cls} - Sample 2\")\n",
    "        else:\n",
    "            axs[row_idx, col_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47f18e",
   "metadata": {},
   "source": [
    "## Dataset class and data manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a9fcb",
   "metadata": {},
   "source": [
    "### Dataset class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0441cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset1(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None, is_train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory with all the class folders\n",
    "            classes (list): List of class names (subfolder names)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "            is_train (bool): Whether this is training data or not\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        # Default transforms if none provided\n",
    "        if self.transform is None:\n",
    "            if is_train:\n",
    "                self.transform = T.Compose([\n",
    "                    T.RandomResizedCrop(128), # Resize to 128x128\n",
    "                    # T.RandomHorizontalFlip(),\n",
    "                    # T.RandomRotation(15),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(128), # Resize to 128x128\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "\n",
    "        for idx, cls in enumerate(classes):\n",
    "            class_folder = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    self.samples.append((img_path, idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx, retry=0):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            if retry < 3:\n",
    "                return self.__getitem__(random.randint(0, len(self)-1), retry=retry+1)\n",
    "            else:\n",
    "                raise RuntimeError(\"Too many failed image loads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67989cb",
   "metadata": {},
   "source": [
    "### Dataset class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb55162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset2(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None, is_train=True, split_ratio=0.8, seed=42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory with all the class folders\n",
    "            classes (list): List of class names (subfolder names)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "            is_train (bool): Whether this is training data or not\n",
    "            split_ratio (float): Ratio for training data (default is 0.8)\n",
    "            seed (int): Seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        all_samples = []\n",
    "        for idx, cls in enumerate(classes):\n",
    "            class_folder = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    all_samples.append((img_path, idx))\n",
    "\n",
    "        # Shuffle and split once\n",
    "        random.seed(seed)\n",
    "        random.shuffle(all_samples)\n",
    "        split_point = int(len(all_samples) * split_ratio)\n",
    "        if is_train:\n",
    "            self.samples = all_samples[:split_point]\n",
    "        else:\n",
    "            self.samples = all_samples[split_point:]\n",
    "\n",
    "        # Set default transforms if not provided\n",
    "        if self.transform is None:\n",
    "            if is_train:\n",
    "                self.transform = T.Compose([\n",
    "                    T.RandomResizedCrop(128),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(128),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx, retry=0):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            if retry < 3:\n",
    "                return self.__getitem__(random.randint(0, len(self)-1), retry=retry+1)\n",
    "            else:\n",
    "                raise RuntimeError(\"Too many failed image loads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe87c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e39779",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afb3d6",
   "metadata": {},
   "source": [
    "### Model 1: Simple CNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744d80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplenet1(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(Simplenet1, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1), # 128 128 3 -> 128 128 64 \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 128 128 64 -> 64 64 64\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 64 64 64 -> 64 64 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 64 64 128 -> 32 32 128\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # 32 32 128 -> 32 32 256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 32 32 256 -> 16 16 256\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1), # 16 16 256 -> 16 16 512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 16 16 512 -> 8 8 512\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), # 8 8 512 -> 1 1 512\n",
    "            nn.Flatten(), # 1 1 512 -> 512\n",
    "            nn.Linear(512, 256), # 512 -> 256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5), # Dropout layer\n",
    "            nn.Linear(256, 128), # 256 -> 128\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5), # Dropout layer\n",
    "            nn.Linear(128, num_classes), # 128 -> num_classes\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937d1b7",
   "metadata": {},
   "source": [
    "### Model 2: Simple CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57adfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplenet2(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(Simplenet2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False), # 128x128x3 → 128x128x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False), # 128x128x64 → 128x128x64\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 128x128x64 → 64x64x64\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False), # 64x64x64 → 64x64x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False), # 64x64x128 → 64x64x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 64x64x128 → 32x32x128\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False), # 32x32x128 → 32x32x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False), # 32x32x256 → 32x32x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 32x32x256 → 16x16x256\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=False), # 16x16x256 → 16x16x512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False), # 16x16x512 → 16x16x512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 16x16x512 → 8x8x512\n",
    "\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1, bias=False), # 8x8x512 → 8x8x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2) # 8x8x256 → 4x4x256\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                  # 4x4x256 = 4096\n",
    "            nn.Linear(256 * 4 * 4, 512),   # 4096 → 512\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)   # 512 → num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed47e16",
   "metadata": {},
   "source": [
    "### Model 3: Simple CNN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e928dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet3(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleNet3, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2), # 128 128 3 -> 63 63 64\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # 63 63 64 -> 31 31 64\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # 31 31 64 -> 14 14 128\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), #   14 14 128 -> 7 7 128\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2), # 7 7 128 -> 3 3 256\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(288, 144),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(144, 72),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(72, 36),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(36, 18),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(18, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6d285",
   "metadata": {},
   "source": [
    "### Model 4: Simple CNN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3998721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet4(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleNet4, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), # 128 128 3 -> 128 128 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 128 128 32 -> 64 64 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),   # 64 64 32 -> 64 64 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 64 64 64 -> 32 32 64\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 32 32 64 -> 16 16 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 16 16 128 -> 8 8 128\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),#   -> 4 x 4 x 256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71827b1c",
   "metadata": {},
   "source": [
    "### Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01459865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all_but_last_n(model, n=2):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Get all modules with parameters\n",
    "    modules_with_params = [m for m in model.modules() if any(p.requires_grad is False for p in m.parameters())]\n",
    "\n",
    "    # Unfreeze last n modules with parameters\n",
    "    for module in modules_with_params[-n:]:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def print_trainable_params(model):\n",
    "    print(\"Trainable Parameters:\")\n",
    "    total = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            # print(f\"{name}: {num_params}\")\n",
    "            total += num_params\n",
    "    print(f\"Total Trainable Parameters: {total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27129ce2",
   "metadata": {},
   "source": [
    "#### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "765af7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for ResNet18:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 11180103\n",
      "Trainable parameters after freezing for ResNet18:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 4615\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(weights='DEFAULT')\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet18:\")\n",
    "print_trainable_params(resnet18)\n",
    "resnet18 = freeze_all_but_last_n(resnet18, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet18:\")\n",
    "print_trainable_params(resnet18)\n",
    "resnet18 = resnet18.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8c709",
   "metadata": {},
   "source": [
    "#### Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "422748e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for ResNet34:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 21288263\n",
      "Trainable parameters after freezing for ResNet34:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 4615\n"
     ]
    }
   ],
   "source": [
    "resnet34 = models.resnet34(weights='DEFAULT')\n",
    "resnet34.fc = nn.Linear(resnet34.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet34:\")\n",
    "print_trainable_params(resnet34)\n",
    "resnet34 = freeze_all_but_last_n(resnet34, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet34:\")\n",
    "print_trainable_params(resnet34)\n",
    "resnet34 = resnet34.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823358aa",
   "metadata": {},
   "source": [
    "#### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7305abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for ResNet50:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 23522375\n",
      "Trainable parameters after freezing for ResNet50:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 18439\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(weights='DEFAULT')\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet50:\")\n",
    "print_trainable_params(resnet50)\n",
    "resnet50 = freeze_all_but_last_n(resnet50, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet50:\")\n",
    "print_trainable_params(resnet50)\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8a9e7",
   "metadata": {},
   "source": [
    "#### Resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5ff0453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for ResNet101:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 42514503\n",
      "Trainable parameters after freezing for ResNet101:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 18439\n"
     ]
    }
   ],
   "source": [
    "resnet101 = models.resnet101(weights='DEFAULT')\n",
    "resnet101.fc = nn.Linear(resnet101.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet101:\")\n",
    "print_trainable_params(resnet101)\n",
    "resnet101 = freeze_all_but_last_n(resnet101, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet101:\")\n",
    "print_trainable_params(resnet101)\n",
    "resnet101 = resnet101.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47913d49",
   "metadata": {},
   "source": [
    "#### Resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf4b3a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for ResNet152:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 58158151\n",
      "Trainable parameters after freezing for ResNet152:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 18439\n"
     ]
    }
   ],
   "source": [
    "resnet152 = models.resnet152(weights='DEFAULT')\n",
    "resnet152.fc = nn.Linear(resnet152.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet152:\")\n",
    "print_trainable_params(resnet152)\n",
    "resnet152 = freeze_all_but_last_n(resnet152, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet152:\")\n",
    "print_trainable_params(resnet152)\n",
    "resnet152 = resnet152.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3574579",
   "metadata": {},
   "source": [
    "#### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67c01ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for VGG16:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 134289223\n",
      "Trainable parameters after freezing for VGG16:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 28679\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(weights='DEFAULT')\n",
    "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for VGG16:\")\n",
    "print_trainable_params(vgg16)\n",
    "vgg16 = freeze_all_but_last_n(vgg16, 1)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for VGG16:\")\n",
    "print_trainable_params(vgg16)\n",
    "vgg16 = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb43f6",
   "metadata": {},
   "source": [
    "#### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c8613e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for AlexNet:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 57032519\n",
      "Trainable parameters after freezing for AlexNet:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 28679\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.alexnet(weights='DEFAULT')\n",
    "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for AlexNet:\")\n",
    "print_trainable_params(alexnet)\n",
    "alexnet = freeze_all_but_last_n(alexnet, 1)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for AlexNet:\")\n",
    "print_trainable_params(alexnet)\n",
    "alexnet = alexnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba3786",
   "metadata": {},
   "source": [
    "#### GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "684ce388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing for GoogLeNet:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 5607079\n",
      "Trainable parameters after freezing for GoogLeNet:\n",
      "Trainable Parameters:\n",
      "Total Trainable Parameters: 7431\n"
     ]
    }
   ],
   "source": [
    "googlenet = models.googlenet(weights='DEFAULT')\n",
    "googlenet.fc = nn.Linear(googlenet.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for GoogLeNet:\")\n",
    "print_trainable_params(googlenet)\n",
    "googlenet = freeze_all_but_last_n(googlenet, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for GoogLeNet:\")\n",
    "print_trainable_params(googlenet)\n",
    "googlenet = googlenet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8202c57",
   "metadata": {},
   "source": [
    "## Using RayTune for different hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845d2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
