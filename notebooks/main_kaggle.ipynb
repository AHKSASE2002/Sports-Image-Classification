{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96738ce2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd29765",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths\n",
    "input_path = \"/kaggle/input/sports-image-classification/dataset/\"\n",
    "working_dir = \"/kaggle/working/dataset/\"\n",
    "train_dir = os.path.join(working_dir, \"train/\")\n",
    "test_dir = os.path.join(working_dir, \"test/\")\n",
    "\n",
    "# Copy everything from input to working dir (if not already done)\n",
    "if not os.path.exists(working_dir):\n",
    "    shutil.copytree(input_path, working_dir)\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(os.path.join(working_dir, \"train.csv\")).set_index(\"image_ID\")\n",
    "test_df = pd.read_csv(os.path.join(working_dir, \"test.csv\")).set_index(\"image_ID\")\n",
    "\n",
    "# Class labels\n",
    "labels = train_df[\"label\"].unique()\n",
    "for label in labels:\n",
    "    os.makedirs(os.path.join(train_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, label), exist_ok=True)\n",
    "\n",
    "# Move training images into label folders\n",
    "for image_id, row in train_df.iterrows():\n",
    "    label = row[\"label\"]\n",
    "    old_path = os.path.join(train_dir, image_id)\n",
    "    new_path = os.path.join(train_dir, label, image_id)\n",
    "    if os.path.exists(old_path):\n",
    "        shutil.move(old_path, new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320553f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CLIP\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']\n",
    "\n",
    "def classify_with_clip(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(text=classes, images=image, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = outputs.logits_per_image.softmax(dim=1)\n",
    "    return classes[probs.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in tqdm(test_df.index):\n",
    "    image_path = os.path.join(test_dir, image_id)\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "    label = classify_with_clip(image_path)\n",
    "    test_df.at[image_id, 'label'] = label\n",
    "    target_path = os.path.join(test_dir, label)\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "    shutil.move(image_path, os.path.join(target_path, image_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c0c9d",
   "metadata": {},
   "source": [
    "## Dataset class and data manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c46df1",
   "metadata": {},
   "source": [
    "### Dataset class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e817446",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset1(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None, is_train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory with all the class folders\n",
    "            classes (list): List of class names (subfolder names)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "            is_train (bool): Whether this is training data or not\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        # Default transforms if none provided\n",
    "        if self.transform is None:\n",
    "            if is_train:\n",
    "                self.transform = T.Compose([\n",
    "                    T.RandomResizedCrop(128), # Resize to 128x128\n",
    "                    # T.RandomHorizontalFlip(),\n",
    "                    # T.RandomRotation(15),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(128), # Resize to 128x128\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "\n",
    "        for idx, cls in enumerate(classes):\n",
    "            class_folder = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    self.samples.append((img_path, idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx, retry=0):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            if retry < 3:\n",
    "                return self.__getitem__(random.randint(0, len(self)-1), retry=retry+1)\n",
    "            else:\n",
    "                raise RuntimeError(\"Too many failed image loads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb334956",
   "metadata": {},
   "source": [
    "### Dataset class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset2(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None, is_train=True, split_ratio=0.8, seed=42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory with all the class folders\n",
    "            classes (list): List of class names (subfolder names)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "            is_train (bool): Whether this is training data or not\n",
    "            split_ratio (float): Ratio for training data (default is 0.8)\n",
    "            seed (int): Seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        all_samples = []\n",
    "        for idx, cls in enumerate(classes):\n",
    "            class_folder = os.path.join(root_dir, cls)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                if img_name.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    all_samples.append((img_path, idx))\n",
    "\n",
    "        # Shuffle and split once\n",
    "        random.seed(seed)\n",
    "        random.shuffle(all_samples)\n",
    "        split_point = int(len(all_samples) * split_ratio)\n",
    "        if is_train:\n",
    "            self.samples = all_samples[:split_point]\n",
    "        else:\n",
    "            self.samples = all_samples[split_point:]\n",
    "\n",
    "        # Set default transforms if not provided\n",
    "        if self.transform is None:\n",
    "            if is_train:\n",
    "                self.transform = T.Compose([\n",
    "                    T.RandomResizedCrop(128),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(128),\n",
    "                    T.ToTensor(),\n",
    "                ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx, retry=0):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            if retry < 3:\n",
    "                return self.__getitem__(random.randint(0, len(self)-1), retry=retry+1)\n",
    "            else:\n",
    "                raise RuntimeError(\"Too many failed image loads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Badminton', 'Cricket', 'Tennis', 'Swimming', 'Soccer', 'Wrestling', 'Karate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223e49e",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23524e9f",
   "metadata": {},
   "source": [
    "### Model 1: Simple CNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b39051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplenet1(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(Simplenet1, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1), # 128 128 3 -> 128 128 64 \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 128 128 64 -> 64 64 64\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 64 64 64 -> 64 64 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 64 64 128 -> 32 32 128\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # 32 32 128 -> 32 32 256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 32 32 256 -> 16 16 256\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1), # 16 16 256 -> 16 16 512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 16 16 512 -> 8 8 512\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), # 8 8 512 -> 1 1 512\n",
    "            nn.Flatten(), # 1 1 512 -> 512\n",
    "            nn.Linear(512, 256), # 512 -> 256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5), # Dropout layer\n",
    "            nn.Linear(256, 128), # 256 -> 128\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5), # Dropout layer\n",
    "            nn.Linear(128, num_classes), # 128 -> num_classes\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e38fd2",
   "metadata": {},
   "source": [
    "### Model 2: Simple CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simplenet2(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(Simplenet2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False), # 128x128x3 → 128x128x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False), # 128x128x64 → 128x128x64\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 128x128x64 → 64x64x64\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False), # 64x64x64 → 64x64x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False), # 64x64x128 → 64x64x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 64x64x128 → 32x32x128\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False), # 32x32x128 → 32x32x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False), # 32x32x256 → 32x32x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 32x32x256 → 16x16x256\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=False), # 16x16x256 → 16x16x512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False), # 16x16x512 → 16x16x512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), # 16x16x512 → 8x8x512\n",
    "\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1, bias=False), # 8x8x512 → 8x8x256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2) # 8x8x256 → 4x4x256\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                  # 4x4x256 = 4096\n",
    "            nn.Linear(256 * 4 * 4, 512),   # 4096 → 512\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)   # 512 → num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a847f8",
   "metadata": {},
   "source": [
    "### Model 3: Simple CNN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet3(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleNet3, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2), # 128 128 3 -> 63 63 64\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # 63 63 64 -> 31 31 64\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # 31 31 64 -> 14 14 128\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), #   14 14 128 -> 7 7 128\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2), # 7 7 128 -> 3 3 256\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(288, 144),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(144, 72),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(72, 36),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(36, 18),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(18, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22fe609",
   "metadata": {},
   "source": [
    "### Model 4: Simple CNN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d26d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet4(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleNet4, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), # 128 128 3 -> 128 128 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 128 128 32 -> 64 64 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),   # 64 64 32 -> 64 64 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 64 64 64 -> 32 32 64\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 32 32 64 -> 16 16 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),  # 16 16 128 -> 8 8 128\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),#   -> 4 x 4 x 256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7011ef0",
   "metadata": {},
   "source": [
    "### Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all_but_last_n(model, n=2):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Get all modules with parameters\n",
    "    modules_with_params = [m for m in model.modules() if any(p.requires_grad is False for p in m.parameters())]\n",
    "\n",
    "    # Unfreeze last n modules with parameters\n",
    "    for module in modules_with_params[-n:]:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def print_trainable_params(model):\n",
    "    print(\"Trainable Parameters:\")\n",
    "    total = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            # print(f\"{name}: {num_params}\")\n",
    "            total += num_params\n",
    "    print(f\"Total Trainable Parameters: {total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e026caf4",
   "metadata": {},
   "source": [
    "#### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(weights='DEFAULT')\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet18:\")\n",
    "print_trainable_params(resnet18)\n",
    "resnet18 = freeze_all_but_last_n(resnet18, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet18:\")\n",
    "print_trainable_params(resnet18)\n",
    "resnet18 = resnet18.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8623b8",
   "metadata": {},
   "source": [
    "#### Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34 = models.resnet34(weights='DEFAULT')\n",
    "resnet34.fc = nn.Linear(resnet34.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet34:\")\n",
    "print_trainable_params(resnet34)\n",
    "resnet34 = freeze_all_but_last_n(resnet34, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet34:\")\n",
    "print_trainable_params(resnet34)\n",
    "resnet34 = resnet34.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407cb31",
   "metadata": {},
   "source": [
    "#### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23edb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights='DEFAULT')\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet50:\")\n",
    "print_trainable_params(resnet50)\n",
    "resnet50 = freeze_all_but_last_n(resnet50, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet50:\")\n",
    "print_trainable_params(resnet50)\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c5d99",
   "metadata": {},
   "source": [
    "#### Resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101 = models.resnet101(weights='DEFAULT')\n",
    "resnet101.fc = nn.Linear(resnet101.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet101:\")\n",
    "print_trainable_params(resnet101)\n",
    "resnet101 = freeze_all_but_last_n(resnet101, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet101:\")\n",
    "print_trainable_params(resnet101)\n",
    "resnet101 = resnet101.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f284d",
   "metadata": {},
   "source": [
    "#### Resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152 = models.resnet152(weights='DEFAULT')\n",
    "resnet152.fc = nn.Linear(resnet152.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for ResNet152:\")\n",
    "print_trainable_params(resnet152)\n",
    "resnet152 = freeze_all_but_last_n(resnet152, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for ResNet152:\")\n",
    "print_trainable_params(resnet152)\n",
    "resnet152 = resnet152.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb9be4",
   "metadata": {},
   "source": [
    "#### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b269e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(weights='DEFAULT')\n",
    "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for VGG16:\")\n",
    "print_trainable_params(vgg16)\n",
    "vgg16 = freeze_all_but_last_n(vgg16, 1)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for VGG16:\")\n",
    "print_trainable_params(vgg16)\n",
    "vgg16 = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23abb0c",
   "metadata": {},
   "source": [
    "#### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb27f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(weights='DEFAULT')\n",
    "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for AlexNet:\")\n",
    "print_trainable_params(alexnet)\n",
    "alexnet = freeze_all_but_last_n(alexnet, 1)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for AlexNet:\")\n",
    "print_trainable_params(alexnet)\n",
    "alexnet = alexnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe5c3e",
   "metadata": {},
   "source": [
    "#### GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4049610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.googlenet(weights='DEFAULT')\n",
    "googlenet.fc = nn.Linear(googlenet.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "\n",
    "print(\"Trainable parameters before freezing for GoogLeNet:\")\n",
    "print_trainable_params(googlenet)\n",
    "googlenet = freeze_all_but_last_n(googlenet, 2)  # Freeze all but the last 2 layers\n",
    "print(\"Trainable parameters after freezing for GoogLeNet:\")\n",
    "print_trainable_params(googlenet)\n",
    "googlenet = googlenet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714e6a6",
   "metadata": {},
   "source": [
    "# Using Optuna for different hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    if model_name == \"resnet18\":\n",
    "        resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        resnet18.fc = nn.Linear(resnet18.fc.in_features, 7)  # Change the output layer to match the number of classes\n",
    "        resnet18 = freeze_all_but_last_n(resnet18, 2)  # Freeze all but the last 2 layers\n",
    "        resnet18 = resnet18.to(device)\n",
    "        return resnet18\n",
    "\n",
    "    elif model_name == \"resnet34\":\n",
    "        resnet34 = models.resnet34(weights='DEFAULT')\n",
    "        resnet34.fc = nn.Linear(resnet34.fc.in_features, 7)\n",
    "        resnet34 = freeze_all_but_last_n(resnet34, 2)\n",
    "        resnet34 = resnet34.to(device)\n",
    "        return resnet34\n",
    "    \n",
    "    elif model_name == \"resnet50\":\n",
    "        resnet50 = models.resnet50(weights='DEFAULT')\n",
    "        resnet50.fc = nn.Linear(resnet50.fc.in_features, 7)\n",
    "        resnet50 = freeze_all_but_last_n(resnet50, 2)\n",
    "        resnet50 = resnet50.to(device)\n",
    "        return resnet50\n",
    "\n",
    "    elif model_name == \"resnet101\":\n",
    "        resnet101 = models.resnet101(weights='DEFAULT')\n",
    "        resnet101.fc = nn.Linear(resnet101.fc.in_features, 7)\n",
    "        resnet101 = freeze_all_but_last_n(resnet101, 2)\n",
    "        resnet101 = resnet101.to(device)\n",
    "        return resnet101\n",
    "    \n",
    "    elif model_name == \"resnet152\":\n",
    "        resnet152 = models.resnet152(weights='DEFAULT')\n",
    "        resnet152.fc = nn.Linear(resnet152.fc.in_features, 7)\n",
    "        resnet152 = freeze_all_but_last_n(resnet152, 2)\n",
    "        resnet152 = resnet152.to(device)\n",
    "        return resnet152\n",
    "    \n",
    "    elif model_name == \"vgg16\":\n",
    "        vgg16 = models.vgg16(weights='DEFAULT')\n",
    "        vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, 7)\n",
    "        vgg16 = freeze_all_but_last_n(vgg16, 1)\n",
    "        vgg16 = vgg16.to(device)\n",
    "        return vgg16\n",
    "    \n",
    "    elif model_name == \"alexnet\":\n",
    "        alexnet = models.alexnet(weights='DEFAULT')\n",
    "        alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, 7)\n",
    "        alexnet = freeze_all_but_last_n(alexnet, 1)\n",
    "        alexnet = alexnet.to(device)\n",
    "        return alexnet\n",
    "    \n",
    "    elif model_name == \"googlenet\":\n",
    "        googlenet = models.googlenet(weights='DEFAULT')\n",
    "        googlenet.fc = nn.Linear(googlenet.fc.in_features, 7)\n",
    "        googlenet = freeze_all_but_last_n(googlenet, 2)\n",
    "        googlenet = googlenet.to(device)\n",
    "        return googlenet\n",
    "    \n",
    "    elif model_name == \"simplenet1\":\n",
    "        return Simplenet1()\n",
    "    \n",
    "    elif model_name == \"simplenet2\":\n",
    "        return Simplenet2()\n",
    "    \n",
    "    elif model_name == \"simplenet3\":\n",
    "        return SimpleNet3()\n",
    "    \n",
    "    elif model_name == \"simplenet4\":\n",
    "        return SimpleNet4()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not recognized. Please choose a valid model name.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(config, transform=None):\n",
    "    dataset_type = config[\"dataset_class\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    seed = 42 \n",
    "\n",
    "    if dataset_type == \"ImageClass1\": # using train and test directories\n",
    "        train_dataset = ImageDataset1(root_dir=train_dir, transform=transform, classes=classes, is_train=True)\n",
    "        val_dataset = ImageDataset1(root_dir=test_dir, transform=transform, classes=classes, is_train=False)\n",
    "    else: # Splitting train into train and validation sets\n",
    "        train_dataset = ImageDataset2(\n",
    "            root_dir=train_dir,\n",
    "            classes=classes,\n",
    "            transform=transform,\n",
    "            is_train=True,\n",
    "            split_ratio=0.8,\n",
    "            seed=seed\n",
    "        )\n",
    "        val_dataset = ImageDataset2(\n",
    "            root_dir=train_dir,\n",
    "            classes=classes,\n",
    "            transform=transform,\n",
    "            is_train=False,\n",
    "            split_ratio=0.8,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return val_loss / len(val_loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee75fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model, method):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            if method == \"xavier\":\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif method == \"kaiming\":\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "\n",
    "def should_initialize(model_type):\n",
    "    return model_type == \"scratch\"  # only initialize scratch models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cafe230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def train_model(config):\n",
    "    _ , model_name = config[\"model_choice\"]\n",
    "    train_loader, val_loader = get_dataloaders(config)\n",
    "\n",
    "    init_method = config[\"init_method\"]\n",
    "\n",
    "    model = load_model(model_name)\n",
    "    model.to(device)\n",
    "    if should_initialize(config[\"model_choice\"][0]) and init_method != \"default\":\n",
    "        initialize_weights(model, init_method)\n",
    "\n",
    "    # Optimizer\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "    else:\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    epochs = config[\"epochs\"]\n",
    "    save_interval = 2 if epochs <= 6 else 50\n",
    "    save_dir = os.path.join(\"/kaggle/working/logs\", \"checkpoints\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    total_batches = len(train_loader)\n",
    "    total_steps = epochs * total_batches\n",
    "    progress_bar = tqdm(total=total_steps, dynamic_ncols=True, desc=\"Training\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Update tqdm\n",
    "            train_loss = running_loss / (i + 1)\n",
    "            train_acc = 100. * correct / total\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix({\n",
    "                \"Epoch\": f\"{epoch+1}/{epochs}\",\n",
    "                \"Train Loss\": f\"{train_loss:.4f}\",\n",
    "                \"Train Acc\": f\"{train_acc:.2f}%\"\n",
    "            })\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate_model(model, val_loader, criterion)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            time_stamp = datetime.now().strftime(\"%Y%m%d_%H\")\n",
    "            unique_config = f\"{model_name}_{config['dataset_class']}_{config['optimizer']}_{config['init_method']}_{config['batch_size']}_{config['lr']}_time_{time_stamp}\"\n",
    "            os.makedirs(os.path.join(save_dir, unique_config), exist_ok=True)\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, unique_config, f\"epoch_{epoch+1}.pt\"))\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 20:\n",
    "                progress_bar.set_description(\"Early Stopping\")\n",
    "                break\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Save metrics\n",
    "    os.makedirs(os.path.join(save_dir, unique_config), exist_ok=True)\n",
    "    torch.save({\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"train_accs\": train_accs,\n",
    "        \"val_accs\": val_accs\n",
    "    }, os.path.join(save_dir, unique_config, \"metrics.pt\"))\n",
    "\n",
    "    return max(val_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ca49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective1(trial):\n",
    "    # Suggest hyperparameters\n",
    "    model_name = trial.suggest_categorical(\"model_name\", [\n",
    "     \"simplenet1\", \"simplenet2\", \"simplenet3\", \"simplenet4\"\n",
    "    ])\n",
    "    init_method = trial.suggest_categorical(\"init_method\", [\"xavier\", \"kaiming\", \"default\"])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    lr = trial.suggest_categorical(\"lr\", [0.1, 0.01, 0.001])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    dataset_class = trial.suggest_categorical(\"dataset_class\", [\"ImageClass1\", \"ImageClass2\"])\n",
    "    \n",
    "    model_type = \"pretrained\" if model_name in [\n",
    "        \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\", \"googlenet\",\n",
    "        \"alexnet\", \"vgg16\"\n",
    "    ] else \"scratch\"\n",
    "    epochs = 150\n",
    "\n",
    "    config = {\n",
    "        \"model_choice\": (model_type, model_name),\n",
    "        \"optimizer\": optimizer_name,\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"dataset_class\": dataset_class,\n",
    "        \"epochs\": epochs,\n",
    "        \"init_method\": init_method,\n",
    "    }\n",
    "\n",
    "    # Training\n",
    "    acc = train_model(config)\n",
    "    return acc  # maximize accuracy\n",
    "\n",
    "def objective2(trial):\n",
    "    # Suggest hyperparameters\n",
    "    model_name = trial.suggest_categorical(\"model_name\", [\n",
    "        \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\", \"googlenet\",\n",
    "        \"alexnet\", \"vgg16\"\n",
    "    ])\n",
    "    init_method = trial.suggest_categorical(\"init_method\", [\"xavier\", \"kaiming\", \"default\"])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    lr = trial.suggest_categorical(\"lr\", [0.1, 0.01, 0.001])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    dataset_class = trial.suggest_categorical(\"dataset_class\", [\"ImageClass1\", \"ImageClass2\"])\n",
    "    \n",
    "    model_type = \"pretrained\" if model_name in [\n",
    "        \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\", \"googlenet\",\n",
    "        \"alexnet\", \"vgg16\"\n",
    "    ] else \"scratch\"\n",
    "    epochs = 8\n",
    "\n",
    "    config = {\n",
    "        \"model_choice\": (model_type, model_name),\n",
    "        \"optimizer\": optimizer_name,\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"dataset_class\": dataset_class,\n",
    "        \"epochs\": epochs,\n",
    "        \"init_method\": init_method,\n",
    "    }\n",
    "\n",
    "    # Training\n",
    "    acc = train_model(config)\n",
    "    return acc  # maximize accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f2aa9",
   "metadata": {},
   "source": [
    "## To Run on a device with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective1, n_trials=100)  # adjust trials as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ee72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective2, n_trials=100)  # adjust trials as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6b57e",
   "metadata": {},
   "source": [
    "# Functions to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb81998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_weights(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "def load_metrics(path):\n",
    "    return torch.load(path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
